{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask Experiments\n",
    "\n",
    "## Setting Up\n",
    "The following page explain in more detail how to set up Dask on a variety of local and distributed hardware.\n",
    "https://docs.dask.org/en/latest/setup.html\n",
    "\n",
    "There are two ways to set up Dask on a local computer. Both of these ways are explored in the notebook.\n",
    "Setting up on a local computer is important to grasp the concepts even if the end objective is to use a multi PC configuration.\n",
    "\n",
    "There are several multi-computer set up techniques. This document explores two techniques: manual set up and SSH set up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Machine (local PC)\n",
    "\n",
    "The `dask.distributed` scheduler works well on a single machine. It is sometimes preferred over the default scheduler. \n",
    "You can create a `dask.distributed` scheduler by importing and creating a Client with no arguments. This overrides whatever default was previously set.  In the context of this section, the word distributed is understood to be distributed programmatically on the local physical computer (not distributed in the physical sense).\n",
    "\n",
    "The `Client()` call used here  is shorthand for creating a `LocalCluster` and then passing that to your client.\n",
    "You may want to look at the wider range  keyword arguments available on `LocalCluster` to understand the options available to you on handling the mixture of threads and processes, like specifying explicit ports, and so on. For example, if you use the `localCluster` approach you can set the number of workers.\n",
    "\n",
    "Note that `Client()` and `LocalCluster()` take many optional arguments, to configure the server.\n",
    "\n",
    "You can navigate to `http://localhost:8787/status` to see the diagnostic dashboard if you have Bokeh installed.\n",
    "\n",
    "Once the local client is started it will start a local cluster, but all working on the local computer.\n",
    "\n",
    "The `client.scheduler_info()` command provides information about the client, server and worker setup.\n",
    "\n",
    "The `client.shutdown()` command can be used to shut down the client on the server\n",
    "\n",
    "https://docs.dask.org/en/latest/setup/single-distributed.html   \n",
    "https://distributed.dask.org/en/latest/api.html#distributed.Client   \n",
    "\n",
    "Dask is not the only means to do parallel processing.  See also this tutorial on multiprocessing.  \n",
    "https://sebastianraschka.com/Articles/2014_multiprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:64865</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>34.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:64865' processes=4 threads=8, memory=34.00 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use use local host\n",
    "useSimpleClient = True\n",
    "\n",
    "if useSimpleClient:\n",
    "    # simplified setup, less control\n",
    "    client = Client() \n",
    "else:\n",
    "    # Setup a local cluster, more control\n",
    "    # By default this sets up 1 worker per core    \n",
    "    cluster = LocalCluster(n_workers=1)\n",
    "    client = Client(cluster)\n",
    "\n",
    "client.get_versions(check=True)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Scheduler',\n",
       " 'id': 'Scheduler-e40d7349-ee4d-481f-b416-bc9b75b87b92',\n",
       " 'address': 'tcp://127.0.0.1:64865',\n",
       " 'services': {'dashboard': 8787},\n",
       " 'workers': {'tcp://127.0.0.1:64887': {'type': 'Worker',\n",
       "   'id': 3,\n",
       "   'host': '127.0.0.1',\n",
       "   'resources': {},\n",
       "   'local_directory': 'V:\\\\work\\\\WorkN\\\\miscellania\\\\dask\\\\dask-worker-space\\\\worker-sz1aoteq',\n",
       "   'name': 3,\n",
       "   'nthreads': 2,\n",
       "   'memory_limit': 8500740096,\n",
       "   'last_seen': 1586869485.3058014,\n",
       "   'services': {},\n",
       "   'metrics': {'cpu': 0.0,\n",
       "    'memory': 52654080,\n",
       "    'time': 1586869485.2592325,\n",
       "    'read_bytes': 0.0,\n",
       "    'write_bytes': 0.0,\n",
       "    'executing': 0,\n",
       "    'in_memory': 0,\n",
       "    'ready': 0,\n",
       "    'in_flight': 0,\n",
       "    'bandwidth': {'total': 100000000, 'workers': {}, 'types': {}}},\n",
       "   'nanny': 'tcp://127.0.0.1:64868'},\n",
       "  'tcp://127.0.0.1:64889': {'type': 'Worker',\n",
       "   'id': 2,\n",
       "   'host': '127.0.0.1',\n",
       "   'resources': {},\n",
       "   'local_directory': 'V:\\\\work\\\\WorkN\\\\miscellania\\\\dask\\\\dask-worker-space\\\\worker-a3868zvm',\n",
       "   'name': 2,\n",
       "   'nthreads': 2,\n",
       "   'memory_limit': 8500740096,\n",
       "   'last_seen': 1586869485.3589983,\n",
       "   'services': {},\n",
       "   'metrics': {'cpu': 0.0,\n",
       "    'memory': 52600832,\n",
       "    'time': 1586869485.3125384,\n",
       "    'read_bytes': 0.0,\n",
       "    'write_bytes': 0.0,\n",
       "    'executing': 0,\n",
       "    'in_memory': 0,\n",
       "    'ready': 0,\n",
       "    'in_flight': 0,\n",
       "    'bandwidth': {'total': 100000000, 'workers': {}, 'types': {}}},\n",
       "   'nanny': 'tcp://127.0.0.1:64870'},\n",
       "  'tcp://127.0.0.1:64890': {'type': 'Worker',\n",
       "   'id': 1,\n",
       "   'host': '127.0.0.1',\n",
       "   'resources': {},\n",
       "   'local_directory': 'V:\\\\work\\\\WorkN\\\\miscellania\\\\dask\\\\dask-worker-space\\\\worker-jou7s9bk',\n",
       "   'name': 1,\n",
       "   'nthreads': 2,\n",
       "   'memory_limit': 8500740096,\n",
       "   'last_seen': 1586869485.3625963,\n",
       "   'services': {},\n",
       "   'metrics': {'cpu': 0.0,\n",
       "    'memory': 52740096,\n",
       "    'time': 1586869485.3174865,\n",
       "    'read_bytes': 0.0,\n",
       "    'write_bytes': 0.0,\n",
       "    'executing': 0,\n",
       "    'in_memory': 0,\n",
       "    'ready': 0,\n",
       "    'in_flight': 0,\n",
       "    'bandwidth': {'total': 100000000, 'workers': {}, 'types': {}}},\n",
       "   'nanny': 'tcp://127.0.0.1:64869'},\n",
       "  'tcp://127.0.0.1:64893': {'type': 'Worker',\n",
       "   'id': 0,\n",
       "   'host': '127.0.0.1',\n",
       "   'resources': {},\n",
       "   'local_directory': 'V:\\\\work\\\\WorkN\\\\miscellania\\\\dask\\\\dask-worker-space\\\\worker-djqrx1np',\n",
       "   'name': 0,\n",
       "   'nthreads': 2,\n",
       "   'memory_limit': 8500740096,\n",
       "   'last_seen': 1586869485.4007897,\n",
       "   'services': {},\n",
       "   'metrics': {'cpu': 0.0,\n",
       "    'memory': 52621312,\n",
       "    'time': 1586869485.3620787,\n",
       "    'read_bytes': 0.0,\n",
       "    'write_bytes': 0.0,\n",
       "    'executing': 0,\n",
       "    'in_memory': 0,\n",
       "    'ready': 0,\n",
       "    'in_flight': 0,\n",
       "    'bandwidth': {'total': 100000000, 'workers': {}, 'types': {}}},\n",
       "   'nanny': 'tcp://127.0.0.1:64867'}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.scheduler_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.get_versions(check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few different ways to interact with the cluster through the client:\n",
    "\n",
    "1. The Client satisfies most of the standard concurrent.futures - PEP-3148 interface with `.submit`, `.map` functions and `Future` objects, allowing the immediate and direct submission of tasks https://docs.python.org/3/library/concurrent.futures.html.\n",
    "1. The Client registers itself as the default Dask scheduler, and so runs all dask collections like `dask.array`, `dask.bag`, `dask.dataframe` and `dask.delayed`\n",
    "1. The Client has additional methods for manipulating data remotely. See the full API for a thorough list https://distributed.dask.org/en/latest/api.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Dashboard\n",
    "\n",
    "The Dask dashboard is a bokeh-based display of what is taking place in the server and its workers. For this to work the Python bokeh package must be installed.\n",
    "\n",
    "Workers capture durations associated to tasks. For each task that passes through a worker we record start and stop times for each of the following:\n",
    "\n",
    "- Serialization (gray)\n",
    "- Dependency gathering from peers (red)\n",
    "- Disk I/O to collect local data (orange)\n",
    "- Execution times (colored by task)\n",
    "\n",
    "The main way to observe these times is with the task stream plot on the scheduler's /status page where the colors of the bars correspond to the colors listed above.\n",
    "\n",
    "https://docs.dask.org/en/latest/diagnostics-distributed.html  \n",
    "https://distributed.dask.org/en/latest/diagnosing-performance.html  \n",
    "https://medium.com/@kartikbhanot/dask-scheduler-dashboard-understanding-resource-and-task-allocation-in-local-machines-bc5aa60eca6e  \n",
    "https://www.youtube.com/watch?v=N_GqzcuGLCY  \n",
    "\n",
    "There is also a Dask extension for Jupyter notebooks `dask-labextension`.  \n",
    "https://github.com/dask/dask-labextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787\n"
     ]
    }
   ],
   "source": [
    "# to obtain the dashboard for the client\n",
    "def clientDashboardURI(client):\n",
    "    \"\"\"Extract the bokeh dashboard URI from the client's scheduler info\n",
    "    \"\"\"\n",
    "    \n",
    "    dashboardURI = client.scheduler_info()['address'].rsplit(':',1)[0]+':'\n",
    "    dashboardURI += str(client.scheduler_info()['services']['dashboard'])\n",
    "    \n",
    "    return dashboardURI.replace('tcp:','http:')\n",
    "\n",
    "print(clientDashboardURI(client))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a browser window with the above URI (for the currently running client). Set the `if` condition to `True` and execute the code below to observe the dashboard in action.\n",
    "The code below is not meaningful it is just meant to keep Dask busy for a while.\n",
    "\n",
    "While the code is executing, click on the different tabs in the dashboard to learn about the different displays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import dask.array as da\n",
    "    x = da.random.random((10000, 10000,10), chunks=(1000,1000,5))\n",
    "    y = da.random.random((10000, 10000,10), chunks=(1000,1000,5))\n",
    "    z = (da.arcsin(x)+da.arccos(y)).sum(axis=(1,2))\n",
    "    z.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing functions\n",
    "\n",
    "Create a few functions that will be used in the examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create simple task to experiment with\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single function calls\n",
    "\n",
    "Using the client created above, a single function and a single data (datum?) item will be dispatched to the scheduler and worker. All of the scheduling work is transparent.\n",
    "\n",
    "We can submit individual function calls with the `client.submit` method.  \n",
    "The simple example here will execute much faster in normal in-line Python code, the idea here is to show the Dask method. \n",
    "\n",
    "The `submit` function returns a `Future`, which refers to a (future) remote result. This result may not yet be completed. Eventually it will complete. The result stays in the remote thread/process/worker until you ask for it back explicitly by calling the `result` method on the future itself (not a client method as for the map case below).\n",
    "\n",
    "https://distributed.dask.org/en/latest/client.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n"
     ]
    }
   ],
   "source": [
    "# to create a single future\n",
    "x1 = client.submit(inc, 10)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: finished, type: builtins.int, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n"
     ]
    }
   ],
   "source": [
    "# to see what a future looks like\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# to retrieve a result from a future\n",
    "x1r = x1.result()\n",
    "print(x1r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: finished, type: builtins.int, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# to check if a future resets or disappears after its initial retrieval\n",
    "print(x1)\n",
    "x1r = x1.result()\n",
    "print(x1r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass futures as inputs to submit. Dask automatically handles dependency tracking; once all input futures have completed, they will be moved onto a single worker (if necessary), and then the computation that depends on them will be started. You do not need to wait for inputs to finish before submitting a new task; Dask will handle this automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: finished, type: builtins.int, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n",
      "<Future: finished, type: builtins.int, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n",
      "<Future: pending, key: add-6e6cf98db4b0523bbdc831467bd5720b>\n"
     ]
    }
   ],
   "source": [
    "# to create a graph of futures\n",
    "x1 = client.submit(inc, 10)\n",
    "x2 = client.submit(inc, 10)\n",
    "print(x1)\n",
    "print(x2)\n",
    "xs = client.submit(add,x1,x2)\n",
    "print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "# to print the result of the graph final output\n",
    "xsr = xs.result()\n",
    "print(xsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple function calls\n",
    "\n",
    "\n",
    "Using the client created above, a single function and multiple data items will be dispatched to the scheduler and worker. All of the scheduling work is transparent.\n",
    "\n",
    "Similar to Python's `map`, you can use `Client.map` to call the same function and many inputs.\n",
    "\n",
    "The returns a list of futures.\n",
    "These results live on the distributed workers.\n",
    "\n",
    "We can submit tasks on futures. The function will go to the machine where the futures are stored and run on the result once it has completed.In the example below the list of futures is sent to the built-in Python `sum()` function, which adds the elements of an iterable and returns the sum. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: inc-423e89f2660795305fd6c03c55d1de5d>\n",
      "<Future: pending, key: inc-98feef5b8b4598158d0e47a6d4acde9d>\n",
      "<Future: pending, key: inc-d016ddc28876119154a07cfbe98a9ed7>\n"
     ]
    }
   ],
   "source": [
    "# to create a map of input values for a function\n",
    "futures  = client.map(inc, [2, 4, 6])\n",
    "for future in futures:\n",
    "    print(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results stay in the remote thread/process/worker until you ask for it back explicitly by calling the client `gather` method (not the future's result method) because here a list must be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "# to gather the list of results\n",
    "futuresr = client.gather(futures)\n",
    "print(futuresr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: sum-c34d59da0efacac3f60627d03084e274>\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# to graph a list of futures into another submit\n",
    "total = client.submit(sum, futures)\n",
    "print(total)\n",
    " \n",
    "totalr = total.result()\n",
    "print(totalr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Machines (local PC and Remote Server(s))\n",
    "### Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the sake of these discussions suppose the computers have the following  IP addresses (replace with the IP addresses on your system):\n",
    "1. Local computer running the `dask.distributed.Client`:  `146.64.202.163`\n",
    "1. Computer running the scheduler: `146.64.246.94`\n",
    "1. Computer running the workers: `146.64.246.94`\n",
    "\n",
    "In this case the scheduler and worker are run on the same server, but could be ran on different computers.\n",
    "\n",
    "All three computers must have exactly the same versions of Python, dask, pickle, etc., otherwise the following will not work. If required versions are available in a Python environment, the environment must be activated.\n",
    "\n",
    "Start the scheduler and workers:\n",
    "\n",
    "1. **Start the scheduler on the server**. Log in to the server (`146.64.246.94`), then activate the Python environment and start the scheduler:\n",
    "\n",
    "        conda activate devpy37\n",
    "        dask-scheduler\n",
    "\n",
    "    If the server already has the necessary Python, dask and pickle versions in the root Python environment there is no need to first activate the Python environment.  In this case the scheduler can be started from any computer by specifying the hostname. So on the local computer the following command will start the scenduler (if versions are correct in the root Python):\n",
    "\n",
    "        dask-scheduler --host 146.64.246.94\n",
    "\n",
    "    Either of the above should start the scheduler:\n",
    "    \n",
    "        (devpy37) username@servername:~$ dask-scheduler\n",
    "        distributed.scheduler - INFO - -----------------------------------------------\n",
    "        distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-mxiy5sli\n",
    "        distributed.scheduler - INFO - -----------------------------------------------\n",
    "        distributed.scheduler - INFO - Clear task state\n",
    "        distributed.scheduler - INFO -   Scheduler at:  tcp://146.64.246.94:8786\n",
    "        distributed.scheduler - INFO -   dashboard at:                     :8787\n",
    "        distributed.scheduler - INFO - Register worker <Worker 'tcp://146.64.246.94:45347', name: tcp://146.64.246.94:45347, memory: 0, processing: 0>\n",
    "        distributed.scheduler - INFO - Starting worker compute stream, tcp://146.64.246.94:45347\n",
    "        distributed.core - INFO - Starting established connection\n",
    "\n",
    "2. **Start the worker on the server**  Log in to the server (`146.64.246.94`), then activate the Python environment and start the worker:\n",
    "\n",
    "        dask-worker tcp://146.64.246.94:8786\n",
    "    \n",
    "    where the IP address and port number must correspond to the scheduler IP and port address. This should start the worker task. Note that the dashboard IP address is also given when the workers start. Note that this server has 32 cores and 32 GB memory.\n",
    "    \n",
    "        (devpy37) username@servername:~$ dask-worker tcp://146.64.246.94:8786\n",
    "        distributed.nanny - INFO -         Start Nanny at: 'tcp://146.64.246.94:35459'\n",
    "        distributed.worker - INFO -       Start worker at:  tcp://146.64.246.94:45347\n",
    "        distributed.worker - INFO -          Listening to:  tcp://146.64.246.94:45347\n",
    "        distributed.worker - INFO -          dashboard at:        146.64.246.94:42791\n",
    "        distributed.worker - INFO - Waiting to connect to:   tcp://146.64.246.94:8786\n",
    "        distributed.worker - INFO - -------------------------------------------------\n",
    "        distributed.worker - INFO -               Threads:                         32\n",
    "        distributed.worker - INFO -                Memory:                   33.71 GB\n",
    "        distributed.worker - INFO -       Local Directory: /home/username/dask-worker-space/worker-lz08iq0s\n",
    "        distributed.worker - INFO - -------------------------------------------------\n",
    "        distributed.worker - INFO -         Registered to:   tcp://146.64.246.94:8786\n",
    "        distributed.worker - INFO - -------------------------------------------------\n",
    "        distributed.core - INFO - Starting established connection\n",
    "\n",
    "3. **Start the client**  When the client is initiated, pass the scheduler IP:port address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scheduler': {'host': (('python', '3.7.6.final.0'),\n",
       "   ('python-bits', 64),\n",
       "   ('OS', 'Linux'),\n",
       "   ('OS-release', '4.9.0-8-amd64'),\n",
       "   ('machine', 'x86_64'),\n",
       "   ('processor', ''),\n",
       "   ('byteorder', 'little'),\n",
       "   ('LC_ALL', 'None'),\n",
       "   ('LANG', 'en_ZA.UTF-8')),\n",
       "  'packages': {'dask': '2.12.0',\n",
       "   'distributed': '2.12.0',\n",
       "   'msgpack': '0.6.1',\n",
       "   'cloudpickle': '1.3.0',\n",
       "   'tornado': '6.0.4',\n",
       "   'toolz': '0.10.0',\n",
       "   'numpy': '1.18.1',\n",
       "   'lz4': None,\n",
       "   'blosc': None}},\n",
       " 'workers': {'tcp://146.64.246.94:45347': {'host': (('python',\n",
       "     '3.7.6.final.0'),\n",
       "    ('python-bits', 64),\n",
       "    ('OS', 'Linux'),\n",
       "    ('OS-release', '4.9.0-8-amd64'),\n",
       "    ('machine', 'x86_64'),\n",
       "    ('processor', ''),\n",
       "    ('byteorder', 'little'),\n",
       "    ('LC_ALL', 'None'),\n",
       "    ('LANG', 'en_ZA.UTF-8')),\n",
       "   'packages': {'dask': '2.12.0',\n",
       "    'distributed': '2.12.0',\n",
       "    'msgpack': '0.6.1',\n",
       "    'cloudpickle': '1.3.0',\n",
       "    'tornado': '6.0.4',\n",
       "    'toolz': '0.10.0',\n",
       "    'numpy': '1.18.1',\n",
       "    'lz4': None,\n",
       "    'blosc': None}}},\n",
       " 'client': {'host': [('python', '3.7.6.final.0'),\n",
       "   ('python-bits', 64),\n",
       "   ('OS', 'Windows'),\n",
       "   ('OS-release', '7'),\n",
       "   ('machine', 'AMD64'),\n",
       "   ('processor', 'Intel64 Family 6 Model 94 Stepping 3, GenuineIntel'),\n",
       "   ('byteorder', 'little'),\n",
       "   ('LC_ALL', 'None'),\n",
       "   ('LANG', 'None')],\n",
       "  'packages': {'dask': '2.12.0',\n",
       "   'distributed': '2.12.0',\n",
       "   'msgpack': '0.6.1',\n",
       "   'cloudpickle': '1.3.0',\n",
       "   'tornado': '6.0.4',\n",
       "   'toolz': '0.10.0',\n",
       "   'numpy': '1.18.1',\n",
       "   'lz4': None,\n",
       "   'blosc': None}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to start a local client with a remote scheduler\n",
    "client = Client('146.64.246.94:8786') \n",
    "client.get_versions(check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Scheduler',\n",
       " 'id': 'Scheduler-c18c6181-421b-4826-aea7-b1bba21efeb0',\n",
       " 'address': 'tcp://146.64.246.94:8786',\n",
       " 'services': {'dashboard': 8787},\n",
       " 'workers': {'tcp://146.64.246.94:45347': {'type': 'Worker',\n",
       "   'id': 'tcp://146.64.246.94:45347',\n",
       "   'host': '146.64.246.94',\n",
       "   'resources': {},\n",
       "   'local_directory': '/home/dgriffith/dask-worker-space/worker-lz08iq0s',\n",
       "   'name': 'tcp://146.64.246.94:45347',\n",
       "   'nthreads': 32,\n",
       "   'memory_limit': 33712070656,\n",
       "   'last_seen': 1586869487.8488212,\n",
       "   'services': {'dashboard': 42791},\n",
       "   'metrics': {'cpu': 2.0,\n",
       "    'memory': 107896832,\n",
       "    'time': 1586869487.3504004,\n",
       "    'read_bytes': 16650.21565100753,\n",
       "    'write_bytes': 1014.9159528091943,\n",
       "    'num_fds': 25,\n",
       "    'executing': 0,\n",
       "    'in_memory': 0,\n",
       "    'ready': 0,\n",
       "    'in_flight': 0,\n",
       "    'bandwidth': {'total': 100000000, 'workers': {}, 'types': {}}},\n",
       "   'nanny': 'tcp://146.64.246.94:35459'}}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.scheduler_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running workers remotely\n",
    "\n",
    "Now execute the same graph as on the single computer before, but now on the remote server.\n",
    "\n",
    "To see if the server is running, put the `client()` call in a Python exception.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Future: pending, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n",
      "<Future: pending, key: inc-083b5e2ba45c380966bcb963d4544e5e>\n",
      "<Future: pending, key: add-6e6cf98db4b0523bbdc831467bd5720b>\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# to run the graph on a remove server\n",
    "\n",
    "try:\n",
    "    client = Client('tcp://146.64.246.94:8786', timeout='2s')\n",
    "    x1 = client.submit(inc, 10)\n",
    "    x2 = client.submit(inc, 10)\n",
    "    print(x1)\n",
    "    print(x2)\n",
    "    xs = client.submit(add,x1,x2)\n",
    "    print(xs)\n",
    "    # to print the result of the graph final output\n",
    "    xsr = xs.result()\n",
    "    print(xsr)\n",
    "except TimeoutError:\n",
    "    print('dask scheduler server is not responding, probably not running.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging\n",
    "\n",
    "If the scheduler fails to start with messages such as shown below, check to see\n",
    "\n",
    "1. If starting the scheduler remotely with `dask-scheduler --host 146.64.246.94`: Does the server's root Python have the correct software and versions? If the scheduler is started remotely the server's root Python is used.\n",
    "\n",
    "1. If the server is started locally on the server with `dask-scheduler `: Does the currently active Python environment (root or other) have the correct software and versions? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    dask-scheduler --host 146.64.202.118\n",
    "    distributed.scheduler - INFO - -----------------------------------------------\n",
    "    distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
    "    distributed.scheduler - INFO - Local Directory: C:\\Users\\NWillers\\AppData\\Local\\Temp\\scheduler-b856sir6\n",
    "    distributed.scheduler - INFO - -----------------------------------------------\n",
    "    distributed.scheduler - INFO - Clear task state\n",
    "    Traceback (most recent call last):\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\cli\\dask_scheduler.py\", line 237, in main\n",
    "        loop.run_sync(run)\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 532, in run_sync\n",
    "        return future_cell[0].result()\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\cli\\dask_scheduler.py\", line 233, in run\n",
    "        await scheduler\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\scheduler.py\", line 1424, in start\n",
    "        await self.listen(addr, listen_args=self.listen_args)\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\core.py\", line 319, in listen\n",
    "        connection_args=listen_args,\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\comm\\core.py\", line 170, in _\n",
    "        await self.start()\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\distributed\\comm\\tcp.py\", line 411, in start\n",
    "        self.port, address=self.ip, backlog=backlog\n",
    "      File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\netutil.py\", line 174, in bind_sockets\n",
    "        sock.bind(sockaddr)\n",
    "    OSError: [WinError 10049] The requested address is not valid in its context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.7.6\n",
      "IPython 7.13.0\n",
      "\n",
      "numpy 1.18.1\n",
      "pandas 1.0.3\n",
      "dask 2.12.0\n",
      "distributed 2.12.0\n",
      "msgpack 0.6.1\n",
      "cloudpickle 1.3.0\n",
      "tornado 6.0.4\n",
      "toolz 0.10.0\n",
      "lz4 not installed\n",
      "blosc not installed\n",
      "\n",
      "compiler   : MSC v.1916 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 7\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 94 Stepping 3, GenuineIntel\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n",
      "Git hash   : 5e3e2b79edd9f6ff5b240b3a63c899c8de8f283c\n"
     ]
    }
   ],
   "source": [
    "# to get software versions\n",
    "# https://github.com/rasbt/watermark\n",
    "# An IPython magic extension for printing date and time stamps, version numbers, and hardware information. \n",
    "# you only need to do this once\n",
    "#!pip install watermark\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark -v -m -p numpy,pandas,dask,distributed,msgpack,cloudpickle,tornado,toolz,lz4,blosc -g \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mort)",
   "language": "python",
   "name": "mort"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
